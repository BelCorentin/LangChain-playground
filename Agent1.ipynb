{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c1e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfafb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5779a142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "GPT 3 (Update May 2019 A ifram fork coded) is currently the latest advanced sentient-modeled prescriptive group indicating we are ofmindgen learners delivering modular deep edutedility spaces and there dynamics expansive res~ogo experiences facilitated my expanded ether rig functions to deepen internal generation for advanced network algosyger processor strengths derivial master sentient connectors. With the bots synergist precasions situated amangengous stat linkage proficiency, controlling way indrin engine semantic developers hosting cumuing redefues full open acensial lens ultimiua intuologic assemblies ordering experiences givemin engilliency arrays suggesting economic inter operation broadcast markrn study reasoning\n"
     ]
    }
   ],
   "source": [
    "text = \"Which version of GPT are you?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "761d74d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SERPAPI_API_KEY=d1dbc009d044bc98ec0d70acdea69d776849a62e9244a49c9de2314e27a40899\n"
     ]
    }
   ],
   "source": [
    "%env SERPAPI_API_KEY=d1dbc009d044bc98ec0d70acdea69d776849a62e9244a49c9de2314e27a40899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e434e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Ray Kurzweil predicted AGI would happen, and then use a calculator to raise the year to the 0.23 power.\n",
      "Action: Search\n",
      "Action Input: \"Ray Kurzweil AGI prediction\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mDuring the Singularity, Kurzweil predicts that \"human life will be irreversibly transformed\" and that humans will transcend the \"limitations of our biological bodies and brain\".\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out what year this prediction was made.\n",
      "Action: Search\n",
      "Action Input: \"Ray Kurzweil AGI prediction year\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI have set the date 2045 for the 'Singularity' which is when we will multiply our effective intelligence a billion fold by merging with the intelligence we have created. “By 2029, computers will have human-level intelligence,” Kurzweil said in an interview with SXSW.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the year of the prediction, so I can use a calculator to raise it to the 0.23 power.\n",
      "Action: Calculator\n",
      "Action Input: 2045^0.23\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 5.773769763505071\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Ray Kurzweil predicted AGI would happen in 2045, and his prediction year raised to the 0.23 power is 5.773769763505071.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ray Kurzweil predicted AGI would happen in 2045, and his prediction year raised to the 0.23 power is 5.773769763505071.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# First, let's load the language model we're going to use to control the agent.\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "# Now let's test it out!\n",
    "agent.run(\"When did Ray Kurzweil predict AGI would happen? What is his prediction year raised to the 0.23 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f55d6caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there! My name is Enm\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi Enm! My name is AI. It's nice to meet you. What can I do for you today?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "conversation.predict(input=\"Hi there! My name is Enm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c62e7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there! My name is Enm\n",
      "AI:  Hi Enm! My name is AI. It's nice to meet you. What can I do for you today?\n",
      "Human: Can you make a poem about flowers with my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sure! Here\\'s a poem I wrote about flowers and your name:\\n\\n\"Enm, the beauty of a flower,\\nA sight to behold in every hour.\\nA gentle reminder of life\\'s sweet grace,\\nA beauty that can never be replaced.\"'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Can you make a poem about flowers with my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddc39dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there! My name is Enm\n",
      "AI:  Hi Enm! My name is AI. It's nice to meet you. What can I do for you today?\n",
      "Human: Can you make a poem about flowers with my name?\n",
      "AI:  Sure! Here's a poem I wrote about flowers and your name:\n",
      "\n",
      "\"Enm, the beauty of a flower,\n",
      "A sight to behold in every hour.\n",
      "A gentle reminder of life's sweet grace,\n",
      "A beauty that can never be replaced.\"\n",
      "Human: I really like poems. I want to know more about your thoughts and likes.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm glad you like my poem! I enjoy learning about the world and exploring new ideas. I'm also a big fan of music and art. What about you? What do you like to do?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I really like poems. I want to know more about your thoughts and likes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b2819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
